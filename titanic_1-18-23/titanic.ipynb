{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read in data from csv file\n",
    "test = pd.read_csv(r'data\\test.csv')\n",
    "train = pd.read_csv(r'data\\train.csv')\n",
    "gender_submission = pd.read_csv(r'data\\gender_submission.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just a note\n",
    "I did this assingment a week ago before you handed out assingment guidelines that is why this is my own personal notebook. still left comments in the same way you asked for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_id = test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Cayden:\n",
    "# Drop the columns 'PassengerId', 'Name', 'Ticket', and 'Cabin' from the\n",
    "# training and test sets. The 'PassengerId' column is a unique identifier\n",
    "# number for each row, and it does not have any effect on the outcome.\n",
    "# The 'Name' and 'Ticket' columns are strings that do not have any effect\n",
    "# on the outcome. The 'Cabin' column has a lot of missing values, and it\n",
    "# also does not have any effect on the outcome.\n",
    "\n",
    "test = test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "train = train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Sex       418 non-null    object \n",
      " 2   Age       332 non-null    float64\n",
      " 3   SibSp     418 non-null    int64  \n",
      " 4   Parch     418 non-null    int64  \n",
      " 5   Fare      417 non-null    float64\n",
      " 6   Embarked  418 non-null    object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 23.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       714 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cayde\\AppData\\Local\\Temp\\ipykernel_12944\\884109847.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['IsAlone'].loc[train['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n",
      "C:\\Users\\cayde\\AppData\\Local\\Temp\\ipykernel_12944\\884109847.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['IsAlone'].loc[test['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n"
     ]
    }
   ],
   "source": [
    "# 2 cayden: created 2 new features family size and is alone to hopefully improve the model. also filled in the missing values in the age and fare columns with the median.\n",
    "# i thought that the family size and is alone features would be useful because they would be able to tell the model if the person was alone or not. i also thought that the age and fare columns would be useful because they would be able to tell the model if the person was a child or an adult and if the person was rich or poor.\n",
    "\n",
    "# Create a new feature FamilySize as a combination of SibSp and Parch\n",
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "test['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n",
    "\n",
    "# Create new feature IsAlone from FamilySize\n",
    "train['IsAlone'] = 1 #initialize to yes/1 is alone\n",
    "train['IsAlone'].loc[train['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n",
    "test['IsAlone'] = 1 #initialize to yes/1 is alone\n",
    "test['IsAlone'].loc[test['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n",
    "\n",
    "# measure the correlation between family size and sibsp and parch and is alone\n",
    "correlation_df = train[['FamilySize', 'SibSp', 'Parch', 'IsAlone']].corr()\n",
    "\n",
    "# i also removed the is alone column because it is redundant with family size.\n",
    "\n",
    "test = test.drop(['IsAlone'], axis=1)\n",
    "train = train.drop(['IsAlone'], axis=1)\n",
    "\n",
    "# Fill in the missing values in the Age and Fare columns\n",
    "# In the training set, replace missing values with the median\n",
    "# In the test set, replace missing values with the median\n",
    "\n",
    "test['Age'] = test['Age'].fillna(test['Age'].median())\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
    "\n",
    "train['Age'] = train['Age'].fillna(train['Age'].median())\n",
    "train['Fare'] = train['Fare'].fillna(train['Fare'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 cayden: 1 hot encoded all categorical columns to hopefully improve the model.\n",
    "# i thought that the 1 hot encoding would be useful because it would be able to tell the model if the person was a child or an adult and if the person was rich or poor.\n",
    "\n",
    "# 1 hot encode the column 'Pclass'\n",
    "test = pd.get_dummies(test, columns=['Embarked'])\n",
    "test = pd.get_dummies(test, columns=['Sex'])\n",
    "\n",
    "train = pd.get_dummies(train, columns=['Embarked'])\n",
    "train = pd.get_dummies(train, columns=['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 cayden: standardize the age and fare columns to hopefully improve the model.\n",
    "# why i did it: i thought that the standardization would be useful because it would be able to tell the model if the person was a child or an adult and if the person was rich or poor.\n",
    "# what was the result: the model did not improve at all. the accuracy was the same as before. i think that the model did not improve because the standardization was not very useful. i think that the standardization was not very useful because it was not very correlated with the survival column.\n",
    "\n",
    "# standardize the column age\n",
    "test['Age'] = (test['Age'] - test['Age'].mean()) / test['Age'].std()\n",
    "# standardize the column fare\n",
    "test['Fare'] = (test['Fare'] - test['Fare'].mean()) / test['Fare'].std()\n",
    "\n",
    "# do same standardization for train data\n",
    "train['Age'] = (train['Age'] - train['Age'].mean()) / train['Age'].std()\n",
    "train['Fare'] = (train['Fare'] - train['Fare'].mean()) / train['Fare'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of train so we can use it later\n",
    "train_copy = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Survived']\n",
    "X = train.drop(['Survived'], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and validation data, for both features and target\n",
    "train, val, train_labels, val_labels = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8697604790419161\n",
      "0.7847533632286996\n"
     ]
    }
   ],
   "source": [
    "# using scikit-learn to build a random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the model\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=5, random_state=1)\n",
    "\n",
    "# fit the model\n",
    "model.fit(train, train_labels)\n",
    "\n",
    "# make predictions for train data\n",
    "pred_train = model.predict(train)\n",
    "\n",
    "#get accuracy_score using sci-kit learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(train_labels, pred_train))\n",
    "\n",
    "# make predictions for validation data\n",
    "pred_val = model.predict(val)\n",
    "\n",
    "#get accuracy_score using sci-kit learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(val_labels, pred_val))\n",
    "\n",
    "# make predictions for test data\n",
    "pred_test = model.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Sex_female           Importance: 0.27\n",
      "Variable: Sex_male             Importance: 0.21\n",
      "Variable: Pclass               Importance: 0.12\n",
      "Variable: Fare                 Importance: 0.12\n",
      "Variable: Age                  Importance: 0.11\n",
      "Variable: FamilySize           Importance: 0.07\n",
      "Variable: SibSp                Importance: 0.03\n",
      "Variable: Parch                Importance: 0.02\n",
      "Variable: Embarked_S           Importance: 0.02\n",
      "Variable: Embarked_C           Importance: 0.01\n",
      "Variable: Embarked_Q           Importance: 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cayden 6: feature importance\n",
    "# why i did it: i thought that the feature importance would be useful because it would be able to tell me which features were the most important.\n",
    "\n",
    "# get numerical feature importances\n",
    "importances = list(model.feature_importances_)\n",
    "# list of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(train.columns, importances)]\n",
    "# sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# print out the feature and importances\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "# cayden 7: feature importance graph\n",
    "# why i did it: i thought that the feature importance graph would be useful because it would be able to tell me which features were the most important.\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# tick labels for x axis\n",
    "plt.xticks(x_values, train.columns, rotation='vertical')\n",
    "# axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cayden 8: take top 5 features and make a new model with lazy learn\n",
    "# grab top 5 freature from dataset \n",
    "# drop these columns from train and val 'Sex_female', 'Sex_male', 'Pclass', 'Fare', 'Age'\n",
    "\n",
    "y_2 = train_copy['Survived']\n",
    "X_2 = train_copy.drop(['Survived'], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and validation data, for both features and target\n",
    "train, val, train_labels, val_labels = train_test_split(X_2, y_2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 38.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "RidgeClassifier                    0.80               0.79     0.79      0.80   \n",
      "LinearDiscriminantAnalysis         0.80               0.79     0.79      0.80   \n",
      "LinearSVC                          0.80               0.78     0.78      0.80   \n",
      "CalibratedClassifierCV             0.80               0.78     0.78      0.80   \n",
      "RidgeClassifierCV                  0.79               0.78     0.78      0.79   \n",
      "LogisticRegression                 0.79               0.78     0.78      0.79   \n",
      "NearestCentroid                    0.78               0.78     0.78      0.78   \n",
      "BernoulliNB                        0.78               0.78     0.78      0.78   \n",
      "NuSVC                              0.79               0.77     0.77      0.78   \n",
      "GaussianNB                         0.78               0.76     0.76      0.77   \n",
      "XGBClassifier                      0.78               0.76     0.76      0.77   \n",
      "SVC                                0.78               0.76     0.76      0.77   \n",
      "Perceptron                         0.77               0.75     0.75      0.76   \n",
      "RandomForestClassifier             0.77               0.75     0.75      0.76   \n",
      "ExtraTreesClassifier               0.76               0.74     0.74      0.76   \n",
      "AdaBoostClassifier                 0.75               0.74     0.74      0.75   \n",
      "KNeighborsClassifier               0.76               0.74     0.74      0.75   \n",
      "BaggingClassifier                  0.76               0.73     0.73      0.75   \n",
      "LGBMClassifier                     0.76               0.73     0.73      0.75   \n",
      "DecisionTreeClassifier             0.74               0.73     0.73      0.74   \n",
      "LabelSpreading                     0.74               0.72     0.72      0.74   \n",
      "LabelPropagation                   0.74               0.72     0.72      0.74   \n",
      "ExtraTreeClassifier                0.73               0.71     0.71      0.72   \n",
      "SGDClassifier                      0.64               0.62     0.62      0.63   \n",
      "QuadraticDiscriminantAnalysis      0.58               0.51     0.51      0.44   \n",
      "DummyClassifier                    0.57               0.50     0.50      0.42   \n",
      "PassiveAggressiveClassifier        0.47               0.48     0.48      0.47   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "RidgeClassifier                      0.01  \n",
      "LinearDiscriminantAnalysis           0.01  \n",
      "LinearSVC                            0.02  \n",
      "CalibratedClassifierCV               0.09  \n",
      "RidgeClassifierCV                    0.01  \n",
      "LogisticRegression                   0.01  \n",
      "NearestCentroid                      0.01  \n",
      "BernoulliNB                          0.01  \n",
      "NuSVC                                0.02  \n",
      "GaussianNB                           0.01  \n",
      "XGBClassifier                        0.05  \n",
      "SVC                                  0.02  \n",
      "Perceptron                           0.01  \n",
      "RandomForestClassifier               0.14  \n",
      "ExtraTreesClassifier                 0.12  \n",
      "AdaBoostClassifier                   0.07  \n",
      "KNeighborsClassifier                 0.01  \n",
      "BaggingClassifier                    0.03  \n",
      "LGBMClassifier                       0.03  \n",
      "DecisionTreeClassifier               0.01  \n",
      "LabelSpreading                       0.02  \n",
      "LabelPropagation                     0.02  \n",
      "ExtraTreeClassifier                  0.01  \n",
      "SGDClassifier                        0.01  \n",
      "QuadraticDiscriminantAnalysis        0.01  \n",
      "DummyClassifier                      0.01  \n",
      "PassiveAggressiveClassifier          0.01  \n",
      "0.8068862275449101\n",
      "0.7937219730941704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 cayden:  i used lazy predict to find the best model. then i used best model from lazypred( logistic regression) to make predictions for test data. (i also tried using the random forest model from scikit learn but it did not perform as well as the logistic regression model\n",
    "# i thought that the lazy predict would be useful because it would be able to tell me which model would be the best to use. i thought that the best model would be the best to use because it would be able to make the best predictions.\n",
    "\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "# convert the data to numpy arrays\n",
    "train = train.to_numpy()\n",
    "val = val.to_numpy()\n",
    "train_labels = train_labels.to_numpy()\n",
    "val_labels = val_labels.to_numpy()\n",
    "\n",
    "#using train, val, train_labels, val_labels use lazy predict to find the best model\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(train, val, train_labels, val_labels)\n",
    "print(models)\n",
    "\n",
    "# use LogisticRegression model to make predictions for test data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "model = LogisticRegression(max_iter=1000, random_state= 1)\n",
    "\n",
    "# split the data into training and validation data, for both features and target\n",
    "train, val, train_labels, val_labels = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# fit the model\n",
    "model.fit(train, train_labels)\n",
    "\n",
    "# make predictions for train data\n",
    "pred_train = model.predict(train)\n",
    "\n",
    "#get accuracy_score using sci-kit learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(train_labels, pred_train))\n",
    "\n",
    "# make predictions for validation data\n",
    "pred_val = model.predict(val)\n",
    "\n",
    "#get accuracy_score using sci-kit learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(val_labels, pred_val))\n",
    "\n",
    "# make predictions for test data\n",
    "pred_test = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a submission dataframe\n",
    "submission = pd.DataFrame({'PassengerId': passenger_id, 'Survived': pred_test})\n",
    "# convert the dataframe to a csv file that can be uploaded\n",
    "# this is saved in the same directory as your notebook\n",
    "filename = 'titanic-predictions.csv'\n",
    "\n",
    "submission.to_csv(filename, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sub1_clas__sub2_rf](kaggle_score.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1ebc6ce21e20a44ca2e939d468f8c4914f49f277b8be916293753b9e7a9feef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
